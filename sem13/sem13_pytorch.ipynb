{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Напоминание про нейросетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![активация](active.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![нн](nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![функция активации](activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспоминаем numpy и сравниваем операции в pytorch\n",
    "\n",
    "Мы можем создавать матрицы, перемножать их, складывать, транспонировать и в целом совершать любые матричные операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(5, 3) # создали случайную матрицу \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Добавили 5 :\\n%s\\n\" % (a + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X*X^T  :\\n%s\\n\" % np.dot(a, a.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Среднее по колонкам :\\n%s\\n\" % (a.mean(axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Изменили размеры :\\n%s\\n\" % (a.reshape(3, 5).shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичные операции в **pytorch** выглядят следующим образом, синтаксис отличается, но совсем немного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Проверили размеры : %s\\n\" % (x.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Добавили 5 :\\n%s\\n\" % (x + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X*X^T  (1):\\n%s\\n\" % (torch.matmul(x, x.transpose(0, 1))))\n",
    "print(\"X*X^T  (2):\\n%s\\n\" % (x.mm(x.t())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Среднее по колонкам :\\n%s\\n\" % (x.mean(dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Изменили размеры :\\n%s\\n\" % (x.view([3, 5]).shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшой пример того, как меняются операции:\n",
    "\n",
    "* `x.reshape([1,2,8]) -> x.view(1,2,8)`\n",
    "\n",
    "* `x.sum(axis=-1) -> x.sum(dim=-1)`\n",
    "\n",
    "* `x.astype('int64') -> x.type(torch.LongTensor)`\n",
    "\n",
    "Для помощи вам есть [таблица](https://github.com/torch/torch7/wiki/Torch-for-Numpy-users), которая поможет вам найти аналог операции в numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем тензоры в pytorch и снова изучаем базовые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long) # тензор с нулями и указанием типов чисел\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5.5, 3, 47]) # конструируем тензор из питоновского листа\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float) # создаем матрицу с размерами как у x\n",
    "print(x, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y) # операция сложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.add(x, y) # очередная операция сложения\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(x, y, out=z) # и наконец последний вид\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x * y) # поэлементное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x @ y.t()) # матричное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.mm(y.t())) # и опять матричное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.unsqueeze(0).shape) # добавили измерение в начало, аналог броадкастинга "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.unsqueeze(0).squeeze(0).shape) # убрали измерение в начале, аналог броадкастинга "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также можем делать обычные срезы и переводить матрицы назад в numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3, 5))\n",
    "x = torch.ones((3, 5))\n",
    "print(np.allclose(x.numpy(), a))\n",
    "print(np.allclose(x.numpy()[:, 1], a[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работаем с градиентами руками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "plt.scatter(boston.data[:, -1], boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pytorch есть возможность при создании тензора указывать нужно ли считать по нему градиент или нет, с помощью параметра `requires_grad`. Когда `requires_grad=True` мы сообщаем фреймворку, о том, что мы хотим следить за всеми тензорами, которые получаются из созданного. Иными словами, у любого тензора, у которого указан данный параметр, будет доступ к цепочке операций и преобразований совершенными с ними. Если эти функции дифференцируемые, то у тензора появляется параметр `.grad`, в котором хранится значение градиента.\n",
    "\n",
    "<img src=\"./example1.png\">\n",
    "\n",
    "Если к результирующему тензору применить метод `.backward()`, то фреймворк посчитает по цепочке градиенту для всех тензоров, у которых `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "\n",
    "x = torch.tensor(boston.data[:, -1] / boston.data[:, -1].max(), dtype=torch.float32)\n",
    "y = torch.tensor(boston.target, dtype=torch.float32)\n",
    "\n",
    "assert w.grad is None # только создали тензоры и в них нет градиентов\n",
    "assert b.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = w * x +  b # и опять совершаем операции с тензорами\n",
    "loss = torch.mean((y_pred - y)**2) # совершаем операции с тензорами\n",
    "loss.backward() # считаем градиенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w.grad is not None # сделали операции и посчитали градиенты, значение должно было появится\n",
    "assert b.grad is not None\n",
    "\n",
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(1000):\n",
    "\n",
    "    y_pred = w * x +  b\n",
    "    loss = torch.mean((y_pred - y)**2)\n",
    "    loss.backward()\n",
    "\n",
    "    # делаем шаг градиентного спуска с lr = .05\n",
    "    w.data -= 0.05 * w.grad.data \n",
    "    b.data -= 0.05 * b.grad.data\n",
    "\n",
    "    # обнуляем градиенты, чтобы на следующем шаге опять посчитать и не аккумулировать их\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    # рисуем картинки\n",
    "    if (i+1) % 5 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "        plt.scatter(x.data.numpy(), y_pred.data.numpy(),\n",
    "                    color='orange', linewidth=5)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.data.numpy())\n",
    "        if loss.data.numpy() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моя первая нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы разобраться как обучать нейросите в pytorch, нужно освоить три вещи: \n",
    "\n",
    "1. Как формировать батчи \n",
    "2. Как сделать сетку\n",
    "3. Как написать цикл обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как формировать батчи\n",
    "\n",
    "Чтобы в данном фреймворке иметь возможность итерироваться по данным и применять к ним преобразования, например, аугментации, о которых вы узнаете позже - нужно создать свой класс унаследованный от `torch.utils.data.Dataset`.\n",
    "\n",
    "Вот пример из документации:\n",
    "\n",
    "```\n",
    "class FaceLandmarksDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "```\n",
    "\n",
    "Как вы видите, у такого класса должно быть два метода: \n",
    "\n",
    "* `__len__` -- возвращает информацию о том, сколько объектов у нас в датасете\n",
    "* `__getitem__` -- возвращает семпл и таргет к нему\n",
    "\n",
    "\n",
    "Теперь давайте напишем такой сами, в качестве датасета сгенерируем рандомные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Our random dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'sample': torch.tensor(x[idx, :], dtype=torch.float), 'target': y[idx]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 5)\n",
    "y = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_dataset = RandomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы из данных получать батчи в pytorch используется такая сущность как даталоадер, который принимает на вход класс, унаследованный от `torch.utils.data.Dataset`. Сейчас посмотрим на пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(our_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работают с ним следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    batch_x = batch['sample']\n",
    "    batch_y = batch['target']\n",
    "    break\n",
    "print('Sample:', batch_x)\n",
    "print('Target:', batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как сделать сетку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы в high-level pytorch создавать нейросети используется модуль `nn`. Нейросеть должна быть унаследована от класса `nn.Module`. Пример как это может выглядеть:\n",
    "\n",
    "```\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.conv1(x))\n",
    "       return F.relu(self.conv2(x))\n",
    "```\n",
    "\n",
    "Как мы видим на данном примере, у данного класса должно быть метод `forward`, который определяет прямой проход нейросети. Также из класса выше видно, что модуль `nn` содержит в себе реализацию большинства слоев, а модуль `nn.functional` -- функций активаций.\n",
    "\n",
    "Есть еще один способ создать нейросеть и давайте его разберем на практике:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear` — линейное преобразование данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.tensor([[1.0, 2.0],\n",
    "                        [2.0,  2.0],\n",
    "                        [0.0,  3.0]])\n",
    "\n",
    "in_features = example.shape[1]  # = 2\n",
    "out_features = 2\n",
    "\n",
    "m = nn.Linear(in_features, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential() # создаем пустую модель, в которую будем добавлять слои\n",
    "model.add_module('l1', nn.Linear(5, 8)) # добавили слой с 5-ю нейронами на вход и 3-мя на выход\n",
    "model.add_module('l2', nn.ReLU()) # добавили функцию активации\n",
    "model.add_module('l3', nn.Linear(8, 3)) # добавили слой с 3-мя нейронами на вход и 5-ю на выход\n",
    "model.add_module('l4', nn.ReLU()) # добавили функцию активации\n",
    "model.add_module('l5', nn.Linear(3, 1)) # добавили слой с 3-мя нейронами на вход и 5-ю на выход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters()) # число параметров, которые обучаются в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(batch_x) # получили предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((y_pred.squeeze(1) - batch_y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как написать цикл обучения\n",
    " \n",
    "Давайте теперь соберем загрузку данных, создание модели и обучим на уже созданном для нас датасете MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    './mnist/', train=True, download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для тренировки\n",
    "mnist_val = torchvision.datasets.MNIST(\n",
    "    './mnist/', train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для валидации\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=4, shuffle=True, num_workers=1\n",
    ") # так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_val, batch_size=4, shuffle=True, num_workers=1\n",
    ") # так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(mnist_train[i][0].squeeze(0).numpy().reshape([28, 28]))\n",
    "    plt.title(str(mnist_train[i][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(), # превращаем картинку 28х28 в вектор размером 784\n",
    "    nn.Linear(784, 128), # входной слой размером 784 нейронов с выходом в 128 нейронов\n",
    "    nn.ReLU(), # функция активации релу\n",
    "    nn.Linear(128, 10), # функция активации релу\n",
    "    nn.Softmax(dim=-1) # софтмакс для получения вероятностного распределения над метками класса\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05) # создаем оптимизатор и передаем туда параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса моделей хранятся в виде матриц и выглядят так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посчитать самим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in model.named_parameters()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "for epoch in range(0,11): # всего у нас будет 10 эпох (10 раз подряд пройдемся по всем батчам из трейна)\n",
    "    for x_train, y_train in tqdm(train_dataloader): # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train) # делаем предсказания\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_train) # считаем лосс\n",
    "        loss.backward() # считаем градиенты обратным проходом\n",
    "        optimizer.step() # обновляем параметры сети\n",
    "        optimizer.zero_grad() # обнуляем посчитанные градиенты параметров\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        mean_val_loss = [] # сюда будем складывать средний лосс по батчам\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad(): # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(val_dataloader): # берем батч из вал лоадера\n",
    "                y_pred = model(x_val) # делаем предсказания\n",
    "                loss = nn.CrossEntropyLoss()(y_pred, y_val) # считаем лосс\n",
    "                mean_val_loss.append(loss.numpy()) # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "        print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "        )) # выводим статистику\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in alexnet.parameters()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные материалы:\n",
    "\n",
    "* [Хорошая книга про pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\n",
    "* [Использование pytorch на GPU](https://pytorch.org/docs/master/notes/cuda.html)\n",
    "* [Pytorch за 60 минут](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* [Как устроено автоматическое дифференцирование в pytorch](http://videolectures.net/site/normal_dl/tag=1129745/deeplearning2017_johnson_automatic_differentiation_01.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
